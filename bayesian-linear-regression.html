<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Meta -->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta charset="utf-8">

    <title>Bayesian Linear Regression &ndash; Gastón Amengual</title>

    <!-- PWA -->
    <link rel="manifest" href="https://gastonamengual.github.io/theme/site.webmanifest">
    <meta name="theme-color" content="#6A1A6A">
    <link rel="apple-touch-icon" sizes="180x180" href="https://gastonamengual.github.io/theme/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://gastonamengual.github.io/theme/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://gastonamengual.github.io/theme/favicon/favicon-16x16.png">
    <link rel="shortcut icon" type="image/png" href="https://gastonamengual.github.io/theme/favicon/favicon-32x32.png">

    <!-- Social -->
    <meta property="article:author" content="Gastón Amengual" />
    <meta property="article:section" content="Machine Learning" />

    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Bayesian Linear Regression"/>
    <meta property="og:description" content="Definition. Frequentists vs Bayesians. Comparison to Linear Regression."/>
    <meta property="og:site_name" content="Gastón Amengual" />
    <meta property="og:url" content="https://gastonamengual.github.io/bayesian-linear-regression.html"/>


    <!-- CSS -->
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Spartan:100,200,300,400,500,600,700,800,900">
    <link rel="stylesheet" type="text/css" href="https://gastonamengual.github.io/theme/style.css">
    <link href='fonts/fonts.css' rel='stylesheet'>
  </head>

  <body>
    <div id="navbar">
        <a href="../index.html"><img src="https://gastonamengual.github.io/theme/gaston_amengual.svg" id="navbar-logo"></a>
        <nav id="navbar-menu">
          <ul>
            
              <li class="navbar-li"><a href="/index.html">Home</a></li>
              <li class="navbar-li"><a href="/pages/about.html">About</a></li>
              <li class="navbar-li"><a href="/pages/portfolio.html">Portfolio</a></li>
              <li class="navbar-li"><a href="/categories.html">Articles</a></li>
          </ul>
        </nav>
    </div>



    <br><br>

    <article class="article-article">
      <header class="col-main article-header">
        <h1>Bayesian Linear Regression</h1>
        <a class="article-category" href="https://gastonamengual.github.io/category/machine-learning.html">Machine Learning</a>
      </header>

      <div class="col-main">
        <section class="article-content">
          <div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">import</span> <span class="nn">pymc3</span> <span class="k">as</span> <span class="nn">pm</span>
</code></pre></div>


<h1>Frequentists vs Bayesians</h1>
<h3>Frequentist approach</h3>
<ol>
<li>
<p>The true parameters are fixed. The data is variable.</p>
</li>
<li>
<p>It fits the variable data to the model. That requires the meeting of the assumptions, as, if they are not met, the model does not guarantees correct results. </p>
</li>
<li>
<p>The output are single fixed parameters.</p>
</li>
<li>
<p>For a Simple Linear Regression, the mean response is a single line.</p>
</li>
<li>
<p>For each parameter, a confidence interval can be calculated. This confidence interval is not part of the output of the model, and it focuses on the variability of the data: when taking many samples, 95% of the time this true fixed parameter will be included in the interval. </p>
</li>
</ol>
<h3>Bayesian approach</h3>
<ol>
<li>
<p>There are no true parameters. The parameters are not fixed, but variable, and the data is fixed.</p>
</li>
<li>
<p>It fits the parameters and the model to the fixed data. This introduces a more experimental approach in which assumptions can be changed or relaxed (such as normality or heteroscedasticity), as it is the model that must adapt to the data, not the data to the model.</p>
</li>
<li>
<p>The output is a probability distribution for each parameter. It does not try to find the single best value of the parameters.</p>
</li>
<li>
<p>For a Simple Linear Regression, the mean response is a set of lines</p>
</li>
<li>
<p>Each parameter distribution has its corresponding credible interval (94% is generally used). This interval is a part of the output (such as the mean or the Std.), as it is the most of the area under the curve of the distribution, not and extra calculation, and focuses on the variability of parameters. </p>
</li>
</ol>
<p>There are two critical advantages of Bayesian estimation. With priors any prior knowledge can be quantified by placing priors on the parameters. For instance, if a parameter is thought likely to be small, a prior with more probability mass on low values can be chosen. Also, uncertainty can be quantified, as one gets not a single estimate of the parameter, but instead a complete posterior distribution about how likely different values of these parameters are. For few data points, the uncertainty in the parameters will be very high and very wide posteriors will be obtained.</p>
<h1>Toy Dataset</h1>
<div class="highlight"><pre><span></span><code><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div>


<p><img alt="image alt text" src="https://gastonamengual.github.io/images/bayesian_linear_regression_1.png"></p>
<h1>Frequentist Linear Regression</h1>
<p>A standard linear regression is defined as</p>
<div class="math">$$Y = \beta_1 X + \beta_0 + \epsilon, \; \text{with} \; \epsilon_i \sim N(0, \sigma^2)$$</div>
<p>The coefficients can be estimated using Ordinary Least Squares (OLS) or Maximum Likelihood.</p>
<div class="highlight"><pre><span></span><code><span class="n">reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">beta_1</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">beta_0</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">intercept_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">y_estimated</span> <span class="o">=</span> <span class="n">beta_1</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">beta_0</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_estimated</span><span class="p">)</span>
</code></pre></div>


<p><img alt="image alt text" src="https://gastonamengual.github.io/images/bayesian_linear_regression_2.png"></p>
<p>In the above frequentist estimation process, the output of the linear regression are single fixed values for both the model parameters (<span class="math">\(\beta_0 = -0.22\)</span> and <span class="math">\(\beta_1 = 10.78\)</span>) and the predictions (the predicted value for <span class="math">\(x_i = 5.8\)</span> is <span class="math">\(\hat{y}_i = 62.28\)</span>).</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">mean_response_95_interval</span><span class="p">(</span><span class="n">x_new</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">residuals</span><span class="p">):</span>
    <span class="n">t_multiplier</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.975</span><span class="p">)</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">residuals</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">x_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">x_mean</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">mean_margin</span> <span class="o">=</span> <span class="n">t_multiplier</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">x_size</span> <span class="o">+</span> <span class="p">(</span><span class="n">x_new</span> <span class="o">-</span> <span class="n">x_mean</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_mean</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">x_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))))</span>
    <span class="k">return</span> <span class="n">mean_margin</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="n">residuals</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">y_estimated</span>
<span class="n">x_new</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">y_estimated_new</span> <span class="o">=</span> <span class="n">beta_0</span> <span class="o">+</span> <span class="n">x_new</span> <span class="o">*</span> <span class="n">beta_1</span>

<span class="n">mean_margin</span> <span class="o">=</span> <span class="n">mean_response_95_interval</span><span class="p">(</span><span class="n">x_new</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">residuals</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Confidence interval for x=2: (</span><span class="si">{</span><span class="n">y_estimated_new</span> <span class="o">-</span> <span class="n">mean_margin</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">y_estimated_new</span> <span class="o">+</span> <span class="n">mean_margin</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
</code></pre></div>


<p>Confidence interval for x=2: (-59.17, 101.84)</p>
<h1>Bayesian Linear Regression</h1>
<p>Bayesian linear regression is an approach to linear regression in which the statistical analysis is undertaken within the context of Bayesian inference.</p>
<p>The expression <span class="math">\(Y = \beta_1 X + \beta_0 + \epsilon, \; \text{with} \; \epsilon_i \sim N(0, \sigma^2)\)</span> can be written as</p>
<div class="math">$$Y \sim N(\beta_1 X + \beta_0, \sigma^2)$$</div>
<p>where</p>
<div class="math">$$\sigma^2 \sim Exp(1)$$</div>
<p>Put in words, <span class="math">\(Y\)</span> is a normally distributed random variable with mean <span class="math">\(\beta_1 X + \beta_0\)</span> (that is, the quantity predicted) and some standard deviation <span class="math">\(\sigma\)</span>.</p>
<div class="highlight"><pre><span></span><code><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">linear_regression_model</span><span class="p">:</span>

    <span class="c1"># Priors</span>
    <span class="n">beta_1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;beta_1&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">beta_0</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;beta_0&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">y_</span> <span class="o">=</span> <span class="n">beta_1</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">beta_0</span>

    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;likelihood&#39;</span><span class="p">,</span> <span class="n">y_</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

    <span class="c1"># Inference: draw posterior sample using NUTS sampling</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">draws</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">8000</span><span class="p">)</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="n">beta_1_samples</span> <span class="o">=</span> <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;beta_1&#39;</span><span class="p">]</span>
<span class="n">beta_0_samples</span> <span class="o">=</span> <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;beta_0&#39;</span><span class="p">]</span>
<span class="n">s_samples</span> <span class="o">=</span> <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;sigma&#39;</span><span class="p">]</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="n">pm</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">beta_0_samples</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">beta_0_samples</span><span class="p">)</span>

<span class="n">pm</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">beta_1_samples</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">beta_1_samples</span><span class="p">)</span>

<span class="n">pm</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">s_samples</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s_samples</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Posterior Distribution for Parameters&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>


<p><img alt="image alt text" src="https://gastonamengual.github.io/images/bayesian_linear_regression_3.png"></p>
<p>The mean of the parameters distributions are very similar to the fixed parameters estimated using OLS.</p>
<h2>Mean response for new point</h2>
<div class="highlight"><pre><span></span><code><span class="k">for</span> <span class="n">beta_0</span><span class="p">,</span> <span class="n">beta_1</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">beta_0_samples</span><span class="p">,</span> <span class="n">beta_1_samples</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">beta_0</span> <span class="o">+</span> <span class="n">beta_1</span><span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</code></pre></div>


<p><img alt="image alt text" src="https://gastonamengual.github.io/images/bayesian_linear_regression_4.png"></p>
<p>Once more, the mean response of a new x point is not a single point, but a credible interval.</p>
<div class="highlight"><pre><span></span><code><span class="n">x_new</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">mean_response_for_x_new</span> <span class="o">=</span> <span class="n">beta_0_samples</span> <span class="o">+</span> <span class="n">beta_1_samples</span> <span class="o">*</span> <span class="n">x_new</span>
<span class="n">_003_quantile</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">mean_response_for_x_new</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">)</span>
<span class="n">_097_quantile</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">mean_response_for_x_new</span><span class="p">,</span> <span class="mf">0.97</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">mean_response_for_x_new</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">_003_quantile</span><span class="p">,</span> <span class="n">_097_quantile</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">_003_quantile</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">_097_quantile</span><span class="p">)</span>
</code></pre></div>


<p><img alt="image alt text" src="https://gastonamengual.github.io/images/bayesian_linear_regression_5.png"></p>
<h1>References</h1>
<p><a href="https://en.wikipedia.org/wiki/Bayesian_linear_regression" target="_blank">Bayesian Linear Regression - Wikipedia</a></p>
<p><a href="https://docs.pymc.io/notebooks/GLM-linear.html" target="_blank">GLM: Linear regression</a></p>
<p><a href="https://towardsdatascience.com/bayesian-linear-regression-in-python-via-pymc3-ab8c2c498211" target="_blank">Bayesian Linear Regression in Python via PyMC3</a></p>
<p><a href="https://towardsdatascience.com/introduction-to-bayesian-linear-regression-e66e60791ea7" target="_blank">Introduction to Bayesian Linear Regression</a></p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
        </section>
      </div>

      <br><br>

    </article>


    <footer>
        <p>
          &copy;
          2021          Gastón Amengual
        </p>
    </footer>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-6KC62F9717"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());
  gtag('config', "G-6KC62F9717");</script>  </body>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    tex2jax: { inlineMath: [["$","$"],["\\(","\\)"]] },
    "HTML-CSS": {
      linebreaks: { automatic: true, width: "container" }
    }
    });
  </script>
</html>