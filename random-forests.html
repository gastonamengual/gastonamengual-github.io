<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Meta -->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta charset="utf-8">

    <title>Random Forests &ndash; Gastón Amengual</title>

    <!-- PWA -->
    <link rel="manifest" href="https://gastonamengual.github.io/theme/site.webmanifest">
    <meta name="theme-color" content="#6A1A6A">
    <link rel="apple-touch-icon" sizes="180x180" href="https://gastonamengual.github.io/theme/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://gastonamengual.github.io/theme/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://gastonamengual.github.io/theme/favicon/favicon-16x16.png">
    <link rel="shortcut icon" type="image/png" href="https://gastonamengual.github.io/theme/favicon/favicon-32x32.png">

    <!-- Social -->
    <meta property="article:author" content="Gastón Amengual" />
    <meta property="article:section" content="Machine Learning" />

    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Random Forests"/>
    <meta property="og:description" content="Definition of Random Forest. Implementation from scratch. Application on classification and regression tasks. Choosing of optimum number of trees."/>
    <meta property="og:site_name" content="Gastón Amengual" />
    <meta property="og:url" content="https://gastonamengual.github.io/random-forests.html"/>


    <!-- CSS -->
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Spartan:100,200,300,400,500,600,700,800,900">
    <link rel="stylesheet" type="text/css" href="https://gastonamengual.github.io/theme/style.css">
    <link href='fonts/fonts.css' rel='stylesheet'>
  </head>

  <body>
    <div id="navbar">
        <a href="../index.html"><img src="https://gastonamengual.github.io/theme/gaston_amengual.svg" id="navbar-logo"></a>
        <nav id="navbar-menu">
          <ul>
            
              <li class="navbar-li"><a href="/index.html">Home</a></li>
              <li class="navbar-li"><a href="/pages/about.html">About</a></li>
              <li class="navbar-li"><a href="/pages/portfolio.html">Portfolio</a></li>
              <li class="navbar-li"><a href="/categories.html">Articles</a></li>
          </ul>
        </nav>
    </div>



    <br><br>

    <article class="article-article">
      <header class="col-main article-header">
        <h1>Random Forests</h1>
        <a class="article-category" href="https://gastonamengual.github.io/category/machine-learning.html">Machine Learning</a>
      </header>

      <div class="col-main">
        <section class="article-content">
          <div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">mode</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span><span class="p">,</span> <span class="n">DecisionTreeRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span> <span class="k">as</span> <span class="n">mae</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>
</code></pre></div>


<h1>Definition</h1>
<p>Random forests are an ensemble learning method for classification and regression. They construct a multitude of decision trees at training time and return the class that is the mode of the classes (classification) or the average prediction (regression) of the individual trees. Random forests solve the overfitting problem of the decision trees, and apply the general technique of bootstrap aggregating. The decision trees are grown deep and the trees are not pruned, and will therefore have both high variance and low bias.</p>
<p>Combining predictions from multiple models in ensembles works better if the predictions from the sub-models are not or at least weakly correlated. In the data, there can be certain features that are very strong predictors for the target output, and will be selected in many trees, causing them to become correlated. To ensure that all trees are uncorrelated, random forests use a modified decision tree algorithm: instead of using all the features, it selects, at each candidate split in the learning process, a random subset of the features. Common choices of number of features are <span class="math">\(\sqrt{\text{num features}}\)</span> and <span class="math">\(log_2(\text{num features})\)</span>.</p>
<p>The only parameters when bagging decision trees is the number of trees to include. This can be chosen by increasing the number of trees on run after run until the accuracy begins to stop showing improvement (e.g. on a cross validation test harness). Very large numbers of models may take a long time to prepare, but will not cause the training data to overfit.</p>
<p>The major disadvantage of random forests is their complexity. They required much more computational resources, due to the large number of decision trees joined together, and they require much more time to train than other comparable algorithms.</p>
<h1>Implementation</h1>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">random_forest_train</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">num_trees</span><span class="p">,</span> <span class="n">task</span><span class="p">):</span>

    <span class="n">num_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">random_forest</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_trees</span><span class="p">):</span>
        <span class="n">indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">X_sample</span><span class="p">,</span> <span class="n">y_sample</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">indexes</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">indexes</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s1">&#39;classification&#39;</span><span class="p">:</span>
            <span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_features</span><span class="o">=</span><span class="s1">&#39;sqrt&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s1">&#39;regression&#39;</span><span class="p">:</span>
            <span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_features</span><span class="o">=</span><span class="s1">&#39;sqrt&#39;</span><span class="p">)</span>

        <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_sample</span><span class="p">,</span> <span class="n">y_sample</span><span class="p">)</span>
        <span class="n">random_forest</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tree</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">random_forest</span>

<span class="k">def</span> <span class="nf">random_forest_predict</span><span class="p">(</span><span class="n">random_forest</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">task</span><span class="p">):</span>
    <span class="n">single_trees_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">for</span> <span class="n">tree</span> <span class="ow">in</span> <span class="n">random_forest</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>

    <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s1">&#39;classification&#39;</span><span class="p">:</span>
        <span class="n">predictions</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">mode</span><span class="p">(</span><span class="n">single_trees_predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s1">&#39;regression&#39;</span><span class="p">:</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">single_trees_predictions</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">predictions</span>
</code></pre></div>


<h1>Classification Application</h1>
<div class="highlight"><pre><span></span><code><span class="n">digits</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_digits</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span>
<span class="n">train_set_X</span><span class="p">,</span> <span class="n">test_set_X</span><span class="p">,</span> <span class="n">train_set_y</span><span class="p">,</span> <span class="n">test_set_y</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="n">num_replicates</span> <span class="o">=</span> <span class="mi">1000</span>
</code></pre></div>


<h2>Optimum Number of Trees</h2>
<p>To find the optimum number of trees, K-Folds Cross-validation will be used to calculate the random forest accuracy for each number of trees. </p>
<div class="highlight"><pre><span></span><code><span class="n">folds</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">folds</span><span class="p">)</span>

<span class="n">num_trees_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">51</span><span class="p">)</span>
<span class="n">num_trees_accuracy</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">num_trees_values</span><span class="p">):</span>

    <span class="n">folds_accuracy</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">train_set_X</span><span class="p">):</span>
        <span class="n">X_train_fold</span><span class="p">,</span> <span class="n">X_test_fold</span> <span class="o">=</span> <span class="n">train_set_X</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">train_set_X</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
        <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">y_test_fold</span> <span class="o">=</span> <span class="n">train_set_y</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">train_set_y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>

        <span class="n">random_forest</span> <span class="o">=</span> <span class="n">random_forest_train</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">num_trees</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s1">&#39;classification&#39;</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">random_forest_predict</span><span class="p">(</span><span class="n">random_forest</span><span class="p">,</span> <span class="n">X_test_fold</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s1">&#39;classification&#39;</span><span class="p">)</span>

        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_fold</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
        <span class="n">folds_accuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>

    <span class="n">num_trees_accuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">folds_accuracy</span><span class="p">)</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="n">accuracy_training_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">num_trees_accuracy</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">num_trees_values</span><span class="p">)</span>

<span class="n">best_n_training</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">accuracy_training_df</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">best_accuracy_training</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">accuracy_training_df</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">accuracy_training_df</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="err">The value of n that presented the best accuracy median in 7 folds is: 35 with value of 0.976</span>
</code></pre></div>


<p><img alt="image alt text" src="https://gastonamengual.github.io/images/random_forests_1.png"></p>
<h2>Predictions: Single Decision Trees vs Random Forest</h2>
<p>The accuracy for 1000 random forest will be calculated, predicting the values of the Test Set using the optimum number of trees value found.</p>
<div class="highlight"><pre><span></span><code><span class="n">accuracies_decision_trees</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">accuracies_random_forests</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_replicates</span><span class="p">)):</span>

    <span class="c1"># Single Decision Tree</span>
    <span class="n">decision_tree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_set_X</span><span class="p">,</span> <span class="n">train_set_y</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">decision_tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_set_X</span><span class="p">)</span> 
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_set_y</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
    <span class="n">accuracies_decision_trees</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>

    <span class="c1"># Random Forest</span>
    <span class="n">random_forest</span> <span class="o">=</span> <span class="n">random_forest_train</span><span class="p">(</span><span class="n">train_set_X</span><span class="p">,</span> <span class="n">train_set_y</span><span class="p">,</span> <span class="n">num_trees</span><span class="o">=</span><span class="n">best_n_training</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s1">&#39;classification&#39;</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">random_forest_predict</span><span class="p">(</span><span class="n">random_forest</span><span class="p">,</span> <span class="n">test_set_X</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s1">&#39;classification&#39;</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_set_y</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
    <span class="n">accuracies_random_forests</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">accuracies_decision_trees</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">accuracies_random_forests</span><span class="p">)</span>
</code></pre></div>


<p><img alt="image alt text" src="https://gastonamengual.github.io/images/random_forests_2.png"></p>
<div class="highlight"><pre><span></span><code><span class="n">overlapping</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">accuracies_decision_trees</span> <span class="o">==</span> <span class="n">accuracies_random_forests</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Histograms overlapping = </span><span class="si">{</span><span class="n">overlapping</span><span class="si">:</span><span class="s1">.0f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="err">Histograms overlapping = 0%</span>
</code></pre></div>


<h1>Regression Application</h1>
<div class="highlight"><pre><span></span><code><span class="n">diabetes</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_diabetes</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">diabetes</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">diabetes</span><span class="o">.</span><span class="n">target</span>
<span class="n">train_set_X</span><span class="p">,</span> <span class="n">test_set_X</span><span class="p">,</span> <span class="n">train_set_y</span><span class="p">,</span> <span class="n">test_set_y</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="n">num_replicates</span> <span class="o">=</span> <span class="mi">1000</span>
</code></pre></div>


<h2>Optimum Number of Trees</h2>
<p>To find the optimum number of trees, K-Folds Cross-validation will be used to calculate the random forest RMSE for each number of trees.</p>
<div class="highlight"><pre><span></span><code><span class="n">folds</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">folds</span><span class="p">)</span>

<span class="n">num_trees_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">51</span><span class="p">)</span>
<span class="n">num_trees_rmse</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">num_trees_values</span><span class="p">):</span>

    <span class="n">folds_rmse</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">train_set_X</span><span class="p">):</span>
        <span class="n">X_train_fold</span><span class="p">,</span> <span class="n">X_test_fold</span> <span class="o">=</span> <span class="n">train_set_X</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">train_set_X</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
        <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">y_test_fold</span> <span class="o">=</span> <span class="n">train_set_y</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">train_set_y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>

        <span class="n">random_forest</span> <span class="o">=</span> <span class="n">random_forest_train</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">num_trees</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s1">&#39;regression&#39;</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">random_forest_predict</span><span class="p">(</span><span class="n">random_forest</span><span class="p">,</span> <span class="n">X_test_fold</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s1">&#39;regression&#39;</span><span class="p">)</span>

        <span class="n">rmse</span> <span class="o">=</span> <span class="n">mae</span><span class="p">(</span><span class="n">y_test_fold</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">folds_rmse</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rmse</span><span class="p">)</span>

    <span class="n">num_trees_rmse</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">folds_rmse</span><span class="p">)</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="n">rmse_training_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">num_trees_rmse</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">num_trees_values</span><span class="p">)</span>

<span class="n">best_n_training</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">rmse_training_df</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">best_accuracy_training</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">rmse_training_df</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">rmse_training_df</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="err">The value of n that presented the best accuracy median in 7 folds is: 38 with value of 54.9</span>
</code></pre></div>


<p><img alt="image alt text" src="https://gastonamengual.github.io/images/random_forests_3.png"></p>
<h2>Predictions: Single Decision Trees vs Random Forest</h2>
<p>The RMSE for 1000 random forest will be calculated, predicting the values of the Test Set using the optimum number of trees value found.</p>
<div class="highlight"><pre><span></span><code><span class="n">rmses_decision_trees</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">rmses_random_forests</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_replicates</span><span class="p">)):</span>

    <span class="c1"># Single Decision Tree</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_set_X</span><span class="p">,</span> <span class="n">train_set_y</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_set_X</span><span class="p">)</span> 
    <span class="n">rmse</span> <span class="o">=</span> <span class="n">mae</span><span class="p">(</span><span class="n">test_set_y</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">rmses_decision_trees</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rmse</span><span class="p">)</span>

    <span class="c1"># Random Forest</span>
    <span class="n">random_forest</span> <span class="o">=</span> <span class="n">random_forest_train</span><span class="p">(</span><span class="n">train_set_X</span><span class="p">,</span> <span class="n">train_set_y</span><span class="p">,</span> <span class="n">num_trees</span><span class="o">=</span><span class="n">best_n_training</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s1">&#39;regression&#39;</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">random_forest_predict</span><span class="p">(</span><span class="n">random_forest</span><span class="p">,</span> <span class="n">test_set_X</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s1">&#39;regression&#39;</span><span class="p">)</span>
    <span class="n">rmse</span> <span class="o">=</span> <span class="n">mae</span><span class="p">(</span><span class="n">test_set_y</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">rmses_random_forests</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rmse</span><span class="p">)</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">rmses_decision_trees</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">rmses_random_forests</span><span class="p">)</span>
</code></pre></div>


<p><img alt="image alt text" src="https://gastonamengual.github.io/images/random_forests_4.png"></p>
<div class="highlight"><pre><span></span><code><span class="n">overlapping</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rmses_random_forests</span> <span class="o">==</span> <span class="n">rmses_decision_trees</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Histograms overlapping = </span><span class="si">{</span><span class="n">overlapping</span><span class="si">:</span><span class="s1">.0f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="err">Histograms overlapping = 0%</span>
</code></pre></div>


<h1>Conclusions</h1>
<p>From the above histograms, it can be observed that the random forest improves the performance of the model significantly, and, as the histograms do not overlap, a random forest is always better than a single decision tree in those data sets. Therefore, it helps to solve the problem of overfitting of the decision trees. Moreover, from the boxplots, it can be concluded that, at a certain point, increasing the number of trees does not improve the performance of the Random Forest significantly.</p>
<h1>References</h1>
<p><a href="https://www.wikiwand.com/en/Random_forest" target="_blank">Random Forest - Wikipedia</a></p>
<p><a href="https://machinelearningmastery.com/bagging-and-random-forest-ensemble-algorithms-for-machine-learning/" target="_blank">Bagging and Random Forest Ensemble Algorithms for Machine Learning</a></p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
        </section>
      </div>

      <br><br>

    </article>


    <footer>
        <p>
          &copy;
          2021          Gastón Amengual
        </p>
    </footer>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-6KC62F9717"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());
  gtag('config', "G-6KC62F9717");</script>  </body>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    tex2jax: { inlineMath: [["$","$"],["\\(","\\)"]] },
    "HTML-CSS": {
      linebreaks: { automatic: true, width: "container" }
    }
    });
  </script>
</html>