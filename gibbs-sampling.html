<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Meta -->
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta charset="utf-8">

    <title>Gibbs Sampling &ndash; Gastón Amengual</title>

    <!-- PWA -->
    <link rel="manifest" href="{static}/images/manifest.json">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="application-name" content="Gastón Amengual">
    <meta name="apple-mobile-web-app-title" content="Gastón Amengual">
    <meta name="theme-color" content="#4a2964">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="apple-touch-icon" sizes="180x180" href="{static}images/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="{static}/images/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="{static}/images/favicon/favicon-16x16.png">

    <!-- Social -->
    <meta property="article:author" content="Gastón Amengual" />
    <meta property="article:section" content="Bayesian Statistics" />
    <meta property="article:published_time" content="2020-10-04" />

    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Gibbs Sampling"/>
    <meta property="og:description" content="."/>
    <meta property="og:site_name" content="Gastón Amengual" />
    <meta property="og:url" content="https://gastonamengual.github.io/gibbs-sampling.html"/>

    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Gibbs Sampling">
    <meta name="twitter:description" content=".">
    <meta name="twitter:url" content="https://gastonamengual.github.io/gibbs-sampling.html">

    <!-- Feed -->

    <!-- CSS -->
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Open+Sans:regular,bold">
    <link rel="stylesheet" type="text/css" href="https://gastonamengual.github.io/theme/css/w3.css">
    <link rel="stylesheet" type="text/css" href="https://gastonamengual.github.io/theme/css/style.css">
    <link rel="stylesheet" type="text/css" href="https://gastonamengual.github.io/theme/css/jqcloud.css">
    <link rel="stylesheet" type="text/css" href="https://gastonamengual.github.io/theme/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="https://gastonamengual.github.io/theme/css/pygments-highlight-github.css">

    <!-- Icon -->

    <!-- JavaScript -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.0/jquery.min.js"></script>
    <script src="https://gastonamengual.github.io/theme/js/jqcloud.min.js"></script>
  </head>

  <body>
    <div class="w3-row w3-card w3-white">
      <header id="header">
        <a href="https://gastonamengual.github.io" id="header-logo" title="Home">GA</a>
        <nav id="header-menu">
          <ul>
            <li class="w3-bottombar w3-border-white w3-hover-border-purple"><a href="https://gastonamengual.github.io/">About</a></li>
            <li class="w3-bottombar w3-border-white w3-hover-border-purple"><a href="https://gastonamengual.github.io/pages/portfolio.html">Portfolio</a></li>
            <li class="w3-bottombar w3-border-white w3-hover-border-purple"><a href="/categories.html">Articles</a></li>
          </ul>
        </nav>
      </header>
    </div>



    <br><br>

    <article>
      <header class="w3-container col-main">
        <h1>Gibbs Sampling</h1>
        <div class="post-info">
          <div class="w3-opacity w3-margin-right w3-margin-bottom" style="flex-grow: 1;">
            <span><time datetime="2020-10-04T00:00:00+02:00">Sun 04 October 2020</time> in <a href="https://gastonamengual.github.io/category/bayesian-statistics.html" title="All articles in category Bayesian Statistics">Bayesian Statistics</a></span>
          </div>
        </div>
      </header>



      <div class="col-main w3-container">
        <section id="content">
          <p><strong>Notebook written by Gastón Amengual.</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">pymc3</span> <span class="k">as</span> <span class="nn">pm</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;bmh&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.titlesize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;lines.linewidth&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;lines.markersize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;xtick.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;ytick.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.prop_cycle&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cycler</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;rebeccapurple&quot;</span><span class="p">,</span> <span class="s2">&quot;darkcyan&quot;</span><span class="p">,</span> <span class="s2">&quot;deepskyblue&quot;</span><span class="p">,</span> <span class="s2">&quot;olivedrab&quot;</span><span class="p">,</span> <span class="s2">&quot;lawngreen&quot;</span><span class="p">,</span> <span class="s2">&quot;darkkhaki&quot;</span><span class="p">,</span> <span class="s2">&quot;darkgoldenrod&quot;</span><span class="p">,</span> <span class="s2">&quot;saddlebrown&quot;</span><span class="p">,</span> <span class="s2">&quot;firebrick&quot;</span><span class="p">,</span> <span class="s2">&quot;deeppink&quot;</span><span class="p">])</span>
</code></pre></div>


<p>Gibbs sampling is a Markov Chain Monte Carlo algorithm for obtaining a sequence of observations which are approximated from a specified multivariate probability distribution when direct sampling is difficult. This sequence can be used to approximate the joint distribution, to approximate the marginal distribution of one of the variables or some subset of the variables, or to compute an integral. Typically, some of the variables correspond to observations whose values are known, and hence do not need to be sampled.</p>
<p>Given any probability target distribution $P(\theta, \phi)$ and a function $g(\theta, \phi)$ proportional to the density of $P$ whose values can be calculated: </p>
<p>$$P(\theta, \phi) \propto g(\theta, \phi)$$</p>
<h2>Full conditional distributions</h2>
<p>Using the chain rule of probability, the posterior $p(\theta, \phi \mid y) = p(\theta \mid \phi, y) \cdot p(\phi \mid y)$. The only difference between $p(\theta, \phi \mid y)$ and $p(\theta \mid \phi, y)$ is multiplication by a factor that does not involve $\theta$. Since $g(\theta, \phi)$ when viewed as a function of $\theta$ is proportional to both these expressions, it might as well be replaced with $p(\theta \mid \phi, y)$ in the update for $\theta$.</p>
<p>This distribution $p(\theta \mid \phi, y)$ is called the full conditional distribution for $\theta$, and can be used instead of $g(\theta, \phi)$ as, in some cases, the full conditional distribution is a standard distribution from which is known how to sample. If that happens, the full conditional distribution is treated as a candidate proposal distribution, and the resulting Metropolis-Hastings acceptance probability becomes exactly 1.</p>
<p>Then,</p>
<p>$$p(\theta \mid \phi, y) \propto p(\theta, \phi \mid y)$$</p>
<p>where $\phi$ is considered a constant number, and </p>
<p>$$p(\phi \mid \theta, y) \propto p(\theta, \phi \mid y)$$ </p>
<p>where $\theta$ is considered a constant number. </p>
<p>It is always started with the full posterior distribution. Thus, the process of finding full conditional distributions is the same as finding the posterior distribution of each parameter, pretending that all other parameters are known.</p>
<h2>Gibbs sampler</h2>
<p>The idea of Gibbs sampling is that multiple parameters can be updated by sampling just one parameter at a time, cycling through all parameters and repeating. To perform the update for one particular parameter, the current values of all other parameters are substituted.</p>
<p>Suppose a joint posterior distribution for two parameters $\theta$ and $\phi$, written $p(\theta, \phi \mid y)$. If the distribution of each parameter at a time, i.e., $p(\theta \mid \phi, y)$ and $p(\phi \mid \theta, y)$, can be found, then these distributions can be sampled as following:</p>
<ol>
<li>Using $\phi_{i-1}$, draw $\theta_i$ from $p(\theta \mid \phi = \phi_{i-1}, y)$.</li>
<li>Using $\theta_i$, draw $\phi_i$ from $p(\phi \mid \theta = \theta_i, y)$.</li>
</ol>
<p>Steps 1 and 2 complete one cycle of the Gibbs sampler and produce the draw for $(\theta_i, \phi_i)$ in one iteration of a MCMC sampler. If there are more than two parameters, that can also be handled. One Gibbs cycle would include an update for each of the parameters.</p>
<h2>Example</h2>
<p>In a particular industry, it is desired to know the growth's mean $\mu$ and variance $\sigma^2$ of the companies. </p>
<p>The data $y$ represent the percent change in total personnel from last year to this year for $n=10$ companies, $y = (1.2, 1.4, -0.5, 0.3, 0.9, 2.3, 1.0, 0.1, 1.3, 1.9)$.</p>
<p>The conjugate prior for $\mu$ with known variance is a normal distribution, and the conjugate prior for $\sigma^2$ with known mean is an inverse gamma.</p>
<p>$$\mu \sim N(\mu,\sigma^2) \quad \rightarrow \quad \text{Prior Distribution for } \mu$$
$$\sigma^2 \sim IG(\nu_0,\beta_0) \quad \rightarrow \quad \text{Prior Distribution for } \sigma^2$$</p>
<p>The likelihood is a normal distribution with unknown mean and unknown variance.</p>
<p>$$y_i | \mu, \sigma^2 \sim N(\mu,\sigma^2), \; i=1,...,n \quad \rightarrow \quad \text{Likelihood Distribution}$$</p>
<p>Because this model is not conjugate, the posterior distribution is not in a standard form from which can be easily sampled. To obtain posterior samples, a Markov chain whose stationary distribution is this posterior distribution is set up. The full posterior distribution is:</p>
<p>$$p( \mu, \sigma^2 \mid y_1, y_2, \ldots, y_n ) \propto (\sigma^2)^{-n/2} \exp \left[ -\frac{\sum_{i=1}^n (y_i - \mu)^2}{2\sigma^2} \right] \exp \left[ -\frac{(\mu - \mu_0)^2}{2\sigma_0^2} \right] (\sigma^2)^{-(\nu_0 + 1)} \exp \left[ -\frac{\beta_0}{\sigma^2} \right] I_{\sigma^2 &gt; 0}(\sigma^2)$$ </p>
<p>The full conditional distributions for $\mu$ assuming $\sigma^2$ is known is</p>
<p>$$p(\mu \mid \sigma^2, y_1, \ldots, y_n) \propto \text{N} \left( \mu \mid \frac{n\bar{y}/\sigma^2 + \mu_0/\sigma_0^2}{n/\sigma^2 + 1/\sigma_0^2}, \, \frac{1}{n/\sigma^2 + 1/\sigma_0^2} \right) $$</p>
<p>The full conditional distributions for $\sigma^2$ assuming $\mu$ is known is</p>
<p>$$p(\sigma^2 \mid \mu, y_1, \ldots, y_n) \propto \text{IG}\left( \sigma^2 \mid \nu_0 + \frac{n}{2}, \, \beta_0 + \frac{\sum_{i=1}^n (y_i - \mu)^2}{2} \right)$$</p>
<div class="highlight"><pre><span></span><code><span class="n">prior_mu</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">prior_sigma2</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">prior_nu</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">prior_beta</span> <span class="o">=</span> <span class="mi">1</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">1.4</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">,</span> <span class="mf">1.9</span><span class="p">])</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">update_mu</span><span class="p">(</span><span class="n">current_mu</span><span class="p">,</span> <span class="n">current_sigma2</span><span class="p">,</span> <span class="n">data_size</span><span class="p">):</span>
    <span class="n">sigma2</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">data_size</span> <span class="o">/</span> <span class="n">current_sigma2</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">prior_sigma2</span><span class="p">)</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="p">(</span><span class="n">data_size</span> <span class="o">*</span> <span class="n">data_mean</span> <span class="o">/</span> <span class="n">current_sigma2</span> <span class="o">+</span> <span class="n">prior_mu</span> <span class="o">/</span> <span class="n">prior_sigma2</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma2</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sigma2</span><span class="p">))</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">update_sigma2</span><span class="p">(</span><span class="n">data_size</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">current_mu</span><span class="p">,</span> <span class="n">prior_nu</span><span class="p">,</span> <span class="n">prior_beta</span><span class="p">):</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">prior_nu</span> <span class="o">+</span> <span class="n">data_size</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">prior_beta</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">data</span> <span class="o">-</span> <span class="n">current_mu</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="mf">2.0</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">nu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">beta</span><span class="p">)</span>
</code></pre></div>


<h2>Implementation</h2>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">gibbs_sampler</span><span class="p">(</span><span class="n">initial_mu</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">data_size</span><span class="p">,</span> <span class="n">data_mean</span><span class="p">):</span>
    <span class="n">mu_chain</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">sigma2_chain</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">current_mu</span> <span class="o">=</span> <span class="n">initial_mu</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
        <span class="n">current_sigma2</span> <span class="o">=</span> <span class="n">update_sigma2</span><span class="p">(</span><span class="n">data_size</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">current_mu</span><span class="p">,</span> <span class="n">prior_nu</span><span class="p">,</span> <span class="n">prior_beta</span><span class="p">)</span>
        <span class="n">current_mu</span> <span class="o">=</span> <span class="n">update_mu</span><span class="p">(</span><span class="n">current_mu</span><span class="p">,</span> <span class="n">current_sigma2</span><span class="p">,</span> <span class="n">data_size</span><span class="p">)</span>

        <span class="n">mu_chain</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_mu</span><span class="p">)</span>
        <span class="n">sigma2_chain</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_sigma2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">mu_chain</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sigma2_chain</span><span class="p">)</span>
</code></pre></div>


<h2>Posterior Sampling</h2>
<div class="highlight"><pre><span></span><code><span class="n">initial_mu</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="n">data_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">data_mean</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="n">mu_chain</span><span class="p">,</span> <span class="n">sigma2_chain</span> <span class="o">=</span> <span class="n">gibbs_sampler</span><span class="p">(</span><span class="n">initial_mu</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">data_size</span><span class="p">,</span> <span class="n">data_mean</span><span class="p">)</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="n">pm</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">mu_chain</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Posterior Distribution for μ&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">pm</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">sigma2_chain</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Posterior Distribution for σ²&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>


<p><img alt="image alt text" src="https://gastonamengual.github.io/images/gibbs_sampling_1.png"></p>
<p><img alt="image alt text" src="https://gastonamengual.github.io/images/gibbs_sampling_2.png"></p>
<h1>References</h1>
<p>Bayesian Statistics: Techniques and Models - University of California Santa Cruz - Coursera </p>
<p>https://www.wikiwand.com/en/Gibbs_sampling</p>
        </section>

        <br><hr>

        <footer>

          <a href="https://www.linkedin.com/sharer.php?u=https%3A//gastonamengual.github.io/gibbs-sampling.html&amp;t=Gast%C3%B3n%20Amengual%3A%20Gibbs%20Sampling" target="_blank" class="w3-btn w3-indigo">
            <i class="fa fa-linkedin"></i> <span>Share article in LinkedIn!</span>
          </a>
    
          <br><br><br>



        </footer>
      </div>
    </article>


    <footer id="footer">
      <div id="footer-copyright" class="w3-center w3-small w3-text-grey w3-padding-48">
        <span>
          &copy;
          2021          Gastón Amengual
        </span>
      </div>
    </footer>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'G-6KC62F9717', 'auto');
      ga('send', 'pageview');
    </script>

  </body>
</html>