<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Meta -->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta charset="utf-8">

    <title>Singular Value Decomposition &ndash; Gastón Amengual</title>

    <!-- PWA -->
    <link rel="manifest" href="https://gastonamengual.github.io/theme/site.webmanifest">
    <meta name="theme-color" content="#6A1A6A">
    <link rel="apple-touch-icon" sizes="180x180" href="https://gastonamengual.github.io/theme/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://gastonamengual.github.io/theme/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://gastonamengual.github.io/theme/favicon/favicon-16x16.png">
    <link rel="shortcut icon" type="image/png" href="https://gastonamengual.github.io/theme/favicon/favicon-32x32.png">

    <!-- Social -->
    <meta property="article:author" content="Gastón Amengual" />
    <meta property="article:section" content="Machine Learning" />

    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Singular Value Decomposition"/>
    <meta property="og:description" content="Theoretical explanation of the SVD. From-scratch Python implementation. Application example on an image."/>
    <meta property="og:site_name" content="Gastón Amengual" />
    <meta property="og:url" content="https://gastonamengual.github.io/singular-value-decomposition.html"/>


    <!-- CSS -->
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Spartan:100,200,300,400,500,600,700,800,900">
    <link rel="stylesheet" type="text/css" href="https://gastonamengual.github.io/theme/style.css">
    <link href='fonts/fonts.css' rel='stylesheet'>
  </head>

  <body>
    <div id="navbar">
        <a href="../index.html"><img src="https://gastonamengual.github.io/theme/gaston_amengual.svg" id="navbar-logo"></a>
        <nav id="navbar-menu">
          <ul>
            
              <li class="navbar-li"><a href="/index.html">Home</a></li>
              <li class="navbar-li"><a href="/pages/about.html">About</a></li>
              <li class="navbar-li"><a href="/pages/portfolio.html">Portfolio</a></li>
              <li class="navbar-li"><a href="/categories.html">Articles</a></li>
          </ul>
        </nav>
    </div>



    <br><br>

    <article class="article-article">
      <header class="col-main article-header">
        <h1>Singular Value Decomposition</h1>
        <a class="article-category" href="https://gastonamengual.github.io/category/machine-learning.html">Machine Learning</a>
      </header>

      <div class="col-main">
        <section class="article-content">
          <div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.image</span> <span class="kn">import</span> <span class="n">imread</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;bmh&quot;</span><span class="p">)</span>
<span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> 
          <span class="s1">&#39;axes.titlesize&#39;</span><span class="p">:</span> <span class="mi">18</span><span class="p">,</span> 
          <span class="s1">&#39;axes.labelsize&#39;</span><span class="p">:</span> <span class="mi">14</span><span class="p">,</span> 
          <span class="s1">&#39;lines.linewidth&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> 
          <span class="s1">&#39;lines.markersize&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> 
          <span class="s1">&#39;xtick.labelsize&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
          <span class="s1">&#39;ytick.labelsize&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> 
          <span class="s1">&#39;axes.prop_cycle&#39;</span><span class="p">:</span> <span class="n">plt</span><span class="o">.</span><span class="n">cycler</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mediumpurple&quot;</span><span class="p">,</span> <span class="s2">&quot;saddlebrown&quot;</span><span class="p">,</span> <span class="s2">&quot;darkcyan&quot;</span><span class="p">,</span> <span class="s2">&quot;olivedrab&quot;</span><span class="p">,</span> <span class="s2">&quot;darkseagreen&quot;</span><span class="p">,</span> <span class="s2">&quot;darkkhaki&quot;</span><span class="p">,</span> <span class="s2">&quot;darkgoldenrod&quot;</span><span class="p">,</span> <span class="s2">&quot;deepskyblue&quot;</span><span class="p">,</span> <span class="s2">&quot;firebrick&quot;</span><span class="p">,</span> <span class="s2">&quot;palevioletred&quot;</span><span class="p">]),}</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</code></pre></div>


<p>Let <span class="math">\(X =\)</span> <span class="math">\(<div class="math">\begin{bmatrix}  | &amp; | &amp; | &amp; | \\  x_1 &amp; x_2 &amp; \dotsc &amp; x_m \\  | &amp; | &amp; | &amp; | \end{bmatrix}</div>\)</span> <span class="math">\(\in \mathbb{C}^{nxm}\)</span> be a matrix representing data points, where:</p>
<ul>
<li>
<p>Each row <span class="math">\(X_k \in \mathbb{C}^m\)</span> is a variable or dimension of the data.</p>
</li>
<li>
<p>Each column <span class="math">\(X_k \in \mathbb{C}^n\)</span> is an observation or measurement from simulations or experiments. The index <span class="math">\(k\)</span> indicates the <span class="math">\(k^{th}\)</span> set of measurements or observations.</p>
</li>
</ul>
<p>The method to be explained is specially useful when <span class="math">\(n \gg m\)</span> (more dimensions than observations), i.e. high dimensional problems, resulting in a tall-skinny matrix, as opposed to a short-fat matrix when <span class="math">\(n \ll m\)</span> (more observations than dimensions).</p>
<p>The <strong>SVD</strong> is a unique matrix decomposition that exists for every complex-values matrix <span class="math">\(X \in \mathbb{C}^{nxm}\)</span>:</p>
<div class="math">$$X = U \Sigma V^* \quad (1)$$</div>
<p>where <span class="math">\(U \in \mathbb{C}^{n \times n}\)</span> and <span class="math">\(V \in \mathbb{C}^{m \times m}\)</span> are unitary matrices<span class="math">\(_{[1]}\)</span>. When <span class="math">\(n \geq m\)</span> the matrix <span class="math">\(\Sigma\)</span> has at most <span class="math">\(m\)</span> non-zero elements on the diagonal, and may be written as <span class="math">\(\Sigma =\)</span> <span class="math">\(<div class="math">\begin{bmatrix} \hat{\Sigma} \\ 0 \end{bmatrix}</div>\)</span>. Therefore, it is possible to exactly represent <span class="math">\(X\)</span> using the <strong>economy SVD</strong>:</p>
<div class="math">$$X = U\Sigma V^* = \hat{U} \hat{\Sigma} V^*$$</div>
<p>where <span class="math">\(\hat{U}\)</span> are the first <span class="math">\(m\)</span> columns of <span class="math">\(U\)</span>. The columns of <span class="math">\(U\)</span> are called <strong>left singular vectors of X</strong> and the columns of V are <strong>right singular vectors</strong>. The diagonal elements of <span class="math">\(\Sigma\)</span>, <span class="math">\(\sigma_i\)</span>, are called <strong>singular values</strong>, and they are ordered so that <span class="math">\(\sigma_{i+1} \leq \sigma_i\)</span>, i.e., from largest to smallest. The rank of <span class="math">\(X\)</span> is equal to the number of non-zero singular values.</p>
<p>SVD generalizes the eigendecomposition of a square normal matrix to any <span class="math">\(m \times n\)</span> matrix via an extension of the polar decomposition. It is numerically stable and provides a hierarchical representation of the data in terms of a new coordinate system defined by dominant correlations within the data. Moreover, the SVD is guaranteed to exist for any matrix, unlike the eigendecomposition.</p>
<p><strong>Geometric Interpretation</strong></p>
<p>If <span class="math">\(M\)</span> is an <span class="math">\(n \times n\)</span> real square matrix, the matrices <span class="math">\(U\)</span> and <span class="math">\(V^T\)</span> can be chosen to be real <span class="math">\(n \times n\)</span>, too, which represent rotations or reflection of the space <span class="math">\(R^n\)</span>, while <span class="math">\(\Sigma\)</span> represents the scaling of each coordinate <span class="math">\(X_i\)</span> by the factor <span class="math">\(\sigma_i\)</span>. Thus the SVD decomposition breaks down any invertible linear transformation of <span class="math">\(R^n\)</span> into a composition of three geometrical transformations: a rotation or reflection (<span class="math">\(V^*\)</span>), a coordinate-by-coordinate scaling (<span class="math">\(\Sigma\)</span>), and a second rotation or reflection (<span class="math">\(U\)</span>).</p>
<h1>Interpretation as dominant correlations</h1>
<p>The SVD is related to an eigenvalue problem involving the correlation matrices <span class="math">\(XX^T\)</span> and <span class="math">\(X^TX\)</span>:</p>
<p><span class="math">\(X^T = V \Sigma U^T\)</span></p>
<p><span class="math">\(XX^T = U \Sigma V^T V \Sigma U^T = U \hat{\Sigma^2} U^T\)</span></p>
<p><span class="math">\(X^TX = V \Sigma U^T U \Sigma V^T = V \hat{\Sigma^2} V^T\)</span></p>
<p>Recalling that <span class="math">\(U\)</span> and <span class="math">\(V\)</span> are unitary, multiplying each equation's side by <span class="math">\(U\)</span> and <span class="math">\(V\)</span>, respectively, <span class="math">\(U\)</span>; <span class="math">\(\Sigma\)</span>; and <span class="math">\(V\)</span> are solutions to the following eigenvalue problems:</p>
<p><span class="math">\(X X^T U = U \hat{\Sigma^2} \quad (2)\)</span></p>
<p><span class="math">\(X^T X V = V \hat{\Sigma^2} \quad (3)\)</span></p>
<ul>
<li>
<p>The non-negative singular values of <span class="math">\(X\)</span> are the square root of the non-negative eigenvalue\s of <span class="math">\(X^TX\)</span> and of <span class="math">\(XX^T\)</span>, and are arranged in descending order by magnitude, and thus the columns of <span class="math">\(U\)</span> are hierarchically ordered by how much correlation they capture in the columns of <span class="math">\(X\)</span>; and the columns of <span class="math">\(V\)</span> similarly captures correlation in the rows of <span class="math">\(X\)</span>.</p>
</li>
<li>
<p>The left-singular vectors of <span class="math">\(X\)</span> are a set of orthonormal eigenvectors of of the correlation matrix <span class="math">\(XX^T\)</span>, </p>
</li>
<li>
<p>The right-singular vectors of <span class="math">\(X\)</span> are a set of orthonormal eigenvectors of <span class="math">\(X^TX\)</span>. </p>
</li>
</ul>
<h3>Notes</h3>
<p><strong>Conjugate transpose</strong></p>
<p>The conjugate transpose or Hermitian transpose of an <span class="math">\(n \times m\)</span> matrix <span class="math">\(A\)</span> with complex entries is the <span class="math">\(n \times m\)</span> matrix obtained from <span class="math">\(A\)</span> by taking the transpose and then taking the complex conjugate of each entry (the complex conjugate of <span class="math">\(a+ib\)</span> is <span class="math">\(a-ib\)</span>, for real numbers <span class="math">\(a\)</span> and <span class="math">\(b\)</span>). It is denoted as <span class="math">\(A^H\)</span> or <span class="math">\(A^*\)</span>. For real matrices, the conjugate transpose is just the transpose, <span class="math">\(A^*=A^T\)</span>.</p>
<p><strong>[1] Unitary vs orthogonal matrix</strong></p>
<p>In linear algebra, a complex square matrix <span class="math">\(U\)</span> is unitary if its conjugate transpose <span class="math">\(U^*\)</span> is also its inverse, that is, if <span class="math">\(UU^* = U^*U = I\)</span>, where <span class="math">\(I\)</span> is the identity matrix. For real numbers, unitary and orthogonal means the same.</p>
<h1>Truncated SVD</h1>
<p>The sum of the squares of the singular values should be equal to the total variance in <span class="math">\(X\)</span>, and each one tells how much of the total variance is accounted for by each singular vector. Often, a <strong>truncated SVD</strong> is calculated, truncating the SVD at a rank <span class="math">\(r\)</span> that captures a pre-determined amount of the variance or energy in the original matrix:</p>
<div class="math">$$a_{ij} = \sum_{k=1}^{r} u_{ik} \sigma_k v_{jk}$$</div>
<h2>Election of <span class="math">\(r\)</span></h2>
<p>Deciding how many singular values to keep (i.e. the rank <span class="math">\(r\)</span>) is one of the most important and contentious decisions when using the SVD. There are many factors, including specifications on the desired rank of the system, the magnitude of noise, and the distribution of the singular values. </p>
<h3>Percentage of explained variance captured</h3>
<p>The SVD can be truncated at a rank <span class="math">\(r\)</span> that captures a pre-determined amount of the variance or energy in the original data, such as <span class="math">\(90%\)</span> or <span class="math">\(99%\)</span> truncation.</p>
<h3>Elbow method</h3>
<p>Other techniques involve identifying "elbows" in the singular value distribution, which may denote the transition from singular values that represent important variance percentage from those that represent low information.</p>
<h3>Gavish-Donoho</h3>
<p>According to <a href="https://arxiv.org/abs/1305.5870">Gavish-Donoho (2014)</a>, for non squared matrices, the optimal value of <span class="math">\(r\)</span> is calculated as <span class="math">\(r = \omega(\beta) \cdot median(S)\)</span>, where <span class="math">\(\beta = \dfrac{n}{m} \; \text{if} \; n &lt; m\)</span> or <span class="math">\(\dfrac{m}{n} \; \text{if} \; m &lt; n\)</span>, and <span class="math">\(\omega(\beta)\)</span> can be found in Table IV in <a href="https://arxiv.org/abs/1305.5870">the original paper</a>.</p>
<h1>Image Approximation</h1>
<div class="highlight"><pre><span></span><code><span class="n">X</span> <span class="o">=</span> <span class="n">imread</span><span class="p">(</span><span class="s1">&#39;piano.jpg&#39;</span><span class="p">)</span> <span class="c1"># https://i.pinimg.com/originals/5a/6b/a1/5a6ba131df34eb9ee9a195f18498c839.jpg</span>

<span class="c1"># Apply SVD</span>
<span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">VT</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Optimal r</span>
<span class="n">beta</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">omega</span> <span class="o">=</span> <span class="mf">2.8582</span>
<span class="n">r_optimal</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">S</span><span class="p">)</span> <span class="o">*</span> <span class="n">omega</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">rs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="n">r_optimal</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">size</span><span class="p">]</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">rs</span><span class="p">):</span>

    <span class="c1"># Approximate matrix by truncating in r</span>
    <span class="n">approximation</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="n">r</span><span class="p">]</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">S</span><span class="p">)[:</span><span class="n">r</span><span class="p">,</span> <span class="p">:</span><span class="n">r</span><span class="p">]</span> <span class="o">@</span> <span class="n">VT</span><span class="p">[:</span><span class="n">r</span><span class="p">,</span> <span class="p">:]</span>

    <span class="c1"># Calculate megabytes used in RAM</span>
    <span class="n">megabytes</span> <span class="o">=</span> <span class="p">(</span><span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="n">r</span><span class="p">]</span><span class="o">.</span><span class="n">nbytes</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">S</span><span class="p">)[:</span><span class="n">r</span><span class="p">,</span> <span class="p">:</span><span class="n">r</span><span class="p">]</span><span class="o">.</span><span class="n">nbytes</span> <span class="o">+</span> <span class="n">VT</span><span class="p">[:</span><span class="n">r</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">nbytes</span><span class="p">)</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>

    <span class="c1"># Calculate variance explained</span>
    <span class="n">variance_explained</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">S</span><span class="p">[:</span><span class="n">r</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">S</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>

    <span class="n">img</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">approximation</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s1"> Singular Values - </span><span class="si">{</span><span class="n">megabytes</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> MB - </span><span class="si">{</span><span class="n">variance_explained</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">% explained&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
    <span class="n">img</span><span class="o">.</span><span class="n">set_cmap</span><span class="p">(</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;SVD on Image Compression&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.08</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">22</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="mf">0.99</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>


<p><img alt="image alt text" src="https://gastonamengual.github.io/images/singular_value_decomposition_1.png"></p>
<div class="highlight"><pre><span></span><code><span class="c1"># VARIANCE EXPLAINED</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">S</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">S</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;cadetblue&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">r_optimal</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">S</span><span class="p">[:</span><span class="n">r_optimal</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">S</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;saddlebrown&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Gavish-Donoho Optimal $r$ Value&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">S</span><span class="p">[:</span><span class="n">r_optimal</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">S</span><span class="p">),</span> <span class="n">xmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="n">r_optimal</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;saddlebrown&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">r_optimal</span><span class="p">,</span> <span class="n">ymin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ymax</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">S</span><span class="p">[:</span><span class="n">r_optimal</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">S</span><span class="p">),</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;saddlebrown&#39;</span><span class="p">)</span>

<span class="n">yticks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">))</span> <span class="o">+</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">S</span><span class="p">[:</span><span class="n">r_optimal</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">S</span><span class="p">)],</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">yticks</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">xticks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">]),</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="p">[</span><span class="n">r_optimal</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">xticks</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$r$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Explained Variance&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Cumulative Explained Variance&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.01</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>


<p><img alt="image alt text" src="https://gastonamengual.github.io/images/singular_value_decomposition_2.png"></p>
<h1>References</h1>
<p><a href="https://en.wikipedia.org/wiki/Singular_value_decomposition" target="_blank">Singular Value Decomposition - Wikipedia</a></p>
<p><a href="https://blog.statsbot.co/singular-value-decomposition-tutorial-52c695315254" target="_blank">Singular Value Decomposition (SVD) Tutorial: Applications, Examples, Exercises</a></p>
<p>Data Driven Science &amp; Engineering Machine Learning, Dynamical Systems, and Control - Brunton &amp; Kutz</p>
<p><a href="https://www.youtube.com/playlist?list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv" target="_blank">Singular Value Decomposition - Steve Brunton</a></p>
<p><a href="https://www.youtube.com/watch?v=P5mlg91as1c&amp;t=819s" target="_blank">Lecture 47 — Singular Value Decomposition | Stanford University</a></p>
<p><a href="https://www.youtube.com/watch?v=UyAfmAZU_WI&amp;t=314s" target="_blank">Lecture 48 — Dimensionality Reduction with SVD | Stanford University</a></p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
        </section>
      </div>

      <br><br>

    </article>


    <footer>
        <p>
          &copy;
          2021          Gastón Amengual
        </p>
    </footer>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-6KC62F9717"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());
  gtag('config', "G-6KC62F9717");</script>  </body>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    tex2jax: { inlineMath: [["$","$"],["\\(","\\)"]] },
    "HTML-CSS": {
      linebreaks: { automatic: true, width: "container" }
    }
    });
  </script>
</html>